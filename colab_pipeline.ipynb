{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully Pipelined Colab Notebook — Data → ~900 TSFresh → Baseline → Siamese → Outputs\n",
    "This notebook runs end-to-end with minimal interaction. Configure parameters in the next cell and run all cells top-to-bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Parameters (edit as needed) =====================================\n",
    "REPO_URL = 'https://github.com/umed-indulkar/Exoplanet-Detection-Project.git'  # GitHub repo URL\n",
    "\n",
    "# Input glob for your light curves (set to your folder of 5000 NPZ files)\n",
    "INPUT_GLOB = 'data/lightcurves_ultraclean_5000/*.npz'\n",
    "\n",
    "# Data ingestion mode: one of 'drive', 'upload', 'urls', 'demo'\n",
    "# If your data is already committed in the repo under data/, set to 'demo' (no ingestion) or leave 'upload' and skip.\n",
    "DATA_MODE = 'upload'\n",
    "# If DATA_MODE == 'drive': folder or glob on Drive to copy from (e.g., '/content/drive/MyDrive/curves/*.npz')\n",
    "DRIVE_DATA_GLOB = '/content/drive/MyDrive/curves/*.npz'\n",
    "# If DATA_MODE == 'urls': list of URLs to download\n",
    "DATA_URLS = []  # e.g., ['https://example.com/file1.npz']\n",
    "\n",
    "# Labels ingestion: one of 'none', 'drive', 'upload', 'url'\n",
    "LABELS_MODE = 'none'\n",
    "LABELS_DRIVE_PATH = '/content/drive/MyDrive/labels/labels.csv'\n",
    "LABELS_URL = ''  # e.g., 'https://example.com/labels.csv'\n",
    "\n",
    "# TSFresh preset: 'efficient' or 'comprehensive' (~900+)\n",
    "TSFRESH_PRESET = 'comprehensive'\n",
    "WORKERS = 4\n",
    "\n",
    "# Training toggles\n",
    "TRAIN_BASELINE = True\n",
    "TRAIN_SIAMESE = True\n",
    "EPOCHS_SIAMESE = 10\n",
    "EMBEDDING_DIM = 32\n",
    "DEVICE = 'auto'  # 'auto'|'cpu'|'cuda'\n",
    "# =======================================================================\n",
    "\n",
    "import os, shutil, sys, subprocess, textwrap\n",
    "from pathlib import Path\n",
    "Path('outputs').mkdir(exist_ok=True); Path('runs').mkdir(exist_ok=True)\n",
    "print('Parameters loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Install dependencies\n",
    "!pip -q install numpy pandas scipy pyyaml matplotlib seaborn tsfresh statsmodels scikit-learn optuna streamlit\n",
    "# Torch CPU wheel (works anywhere). If Colab GPU already has torch, you can skip this safely.\n",
    "!pip -q install torch --index-url https://download.pytorch.org/whl/cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Clone repository\n",
    "import os, shutil\n",
    "if os.path.exists('exocode'):\n",
    "    shutil.rmtree('exocode')\n",
    "!git clone $REPO_URL exocode\n",
    "%cd exocode\n",
    "!python simple_test.py || true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Ingest data (to exocode/data)\n",
    "from pathlib import Path\n",
    "Path('data').mkdir(exist_ok=True)\n",
    "print('DATA_MODE =', DATA_MODE)\n",
    "if DATA_MODE == 'drive':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    !cp -v $DRIVE_DATA_GLOB data/ || true\n",
    "elif DATA_MODE == 'urls':\n",
    "    import urllib.request\n",
    "    for url in DATA_URLS:\n",
    "        name = url.split('/')[-1]\n",
    "        print('Downloading', url)\n",
    "        urllib.request.urlretrieve(url, f'data/{name}')\n",
    "elif DATA_MODE == 'upload':\n",
    "    from google.colab import files\n",
    "    print('Upload .npz/.csv/.fits files...')\n",
    "    uploaded = files.upload()\n",
    "    for name in uploaded:\n",
    "        shutil.move(name, f'data/{name}')\n",
    "elif DATA_MODE == 'demo':\n",
    "    # generate a small synthetic NPZ to demonstrate the pipeline\n",
    "    import numpy as np\n",
    "    t = np.linspace(0, 30, 3000); f = np.ones_like(t) + np.random.normal(0, 0.003, len(t))\n",
    "    for t0 in np.arange(2.5, 30, 5.0):\n",
    "        mask = (np.abs(t - t0) < 0.1)\n",
    "        f[mask] -= 0.01\n",
    "    np.savez('data/demo_curve.npz', time=t, flux=f)\n",
    "else:\n",
    "    print('Unknown DATA_MODE; no data ingested.')\n",
    "print('Data files:', list(Path('data').glob('*'))[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Extract TSFresh features (efficient or comprehensive)\n",
    "preset = TSFRESH_PRESET.lower()\n",
    "assert preset in ('efficient','comprehensive'), 'TSFRESH_PRESET must be efficient or comprehensive'\n",
    "!python -m exodet.cli extract --input \"data/*\" --output outputs/features_tsfresh.csv --tier tsfresh --tsfresh-params $preset --workers $WORKERS\n",
    "import pandas as pd\n",
    "df = pd.read_csv('outputs/features_tsfresh.csv'); print('Extracted:', df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Labels ingestion and merge (optional)\n",
    "import pandas as pd, urllib.request\n",
    "labels_path = None\n",
    "if LABELS_MODE == 'drive':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "    labels_path = LABELS_DRIVE_PATH\n",
    "elif LABELS_MODE == 'upload':\n",
    "    from google.colab import files\n",
    "    print('Upload labels.csv with columns: source,label')\n",
    "    up = files.upload()\n",
    "    if up:\n",
    "        for name in up:\n",
    "            shutil.move(name, 'labels.csv')\n",
    "        labels_path = 'labels.csv'\n",
    "elif LABELS_MODE == 'url' and LABELS_URL:\n",
    "    urllib.request.urlretrieve(LABELS_URL, 'labels.csv')\n",
    "    labels_path = 'labels.csv'\n",
    "else:\n",
    "    print('LABELS_MODE = none (supervised steps will be skipped)')\n",
    "\n",
    "if labels_path and Path(labels_path).exists():\n",
    "    feats = pd.read_csv('outputs/features_tsfresh.csv')\n",
    "    lbls = pd.read_csv(labels_path)\n",
    "    merged = feats.merge(lbls, on='source', how='inner')\n",
    "    merged.to_csv('outputs/features_labeled.csv', index=False)\n",
    "    print('Labeled features:', merged.shape)\n",
    "else:\n",
    "    print('No labels available; continuing without supervised steps.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Train/Evaluate Baseline (RandomForest)\n",
    "import os\n",
    "if TRAIN_BASELINE and os.path.exists('outputs/features_labeled.csv'):\n",
    "    !python -m exodet.cli train --features outputs/features_labeled.csv --target label --model rf --output runs/rf.joblib\n",
    "    !python -m exodet.cli evaluate --model runs/rf.joblib --features outputs/features_labeled.csv --target label\n",
    "else:\n",
    "    print('Skipping baseline (no labels or TRAIN_BASELINE=False).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Train/Evaluate Siamese (deep)\n",
    "import os\n",
    "if TRAIN_SIAMESE and os.path.exists('outputs/features_labeled.csv'):\n",
    "    !python -m exodet.cli train-siamese --features outputs/features_labeled.csv --target label --epochs $EPOCHS_SIAMESE --embedding $EMBEDDING_DIM --device $DEVICE --output runs/siamese.pt\n",
    "    !python -m exodet.cli evaluate-siamese --model runs/siamese.pt --features outputs/features_labeled.csv --target label --device $DEVICE\n",
    "else:\n",
    "    print('Skipping Siamese (no labels or TRAIN_SIAMESE=False).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Download outputs\n",
    "from google.colab import files\n",
    "for p in ['outputs/features_tsfresh.csv','outputs/features_labeled.csv','runs/rf.joblib','runs/siamese.pt']:\n",
    "    if Path(p).exists():\n",
    "        files.download(p)\n",
    "    else:\n",
    "        print('Not found (skipped):', p)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
